{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"/mnt/e/SteamLibrary2/steamapps/common/SlayTheSpire/SpeedTheSpire/DEBUG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# modified from code from https://machinelearningmastery.com/lstm-autoencoders/\n",
    "\n",
    "# lstm autoencoder reconstruct and predict sequence\n",
    "from numpy import array\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/a/3207973\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "datafiles = [f for f in listdir(base_folder) if isfile(join(base_folder, f))]\n",
    "len(datafiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8919"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "\n",
    "for datafilename in datafiles:\n",
    "    fullpath = join(base_folder, datafilename)\n",
    "    with open(fullpath, \"r\") as datafile:\n",
    "        lines = datafile.readlines()\n",
    "        for line in lines:\n",
    "            if line[0] == \"I\":\n",
    "                corpus.append(line[1:-1])\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [[char for char in line] for line in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '?': 1, '%': 2, '!': 3, '.': 4, '$': 5, '\\\\': 6, ':': 7, '_': 8, '-': 9, '(': 10, ')': 11, '{': 12, '}': 13, '[': 14, ']': 15, '\"': 16, ',': 17, '+': 18, 'a': 19, 'b': 20, 'c': 21, 'd': 22, 'e': 23, 'f': 24, 'g': 25, 'h': 26, 'i': 27, 'j': 28, 'k': 29, 'l': 30, 'm': 31, 'n': 32, 'o': 33, 'p': 34, 'q': 35, 'r': 36, 's': 37, 't': 38, 'u': 39, 'v': 40, 'w': 41, 'x': 42, 'y': 43, 'z': 44, 'A': 45, 'B': 46, 'C': 47, 'D': 48, 'E': 49, 'F': 50, 'G': 51, 'H': 52, 'I': 53, 'J': 54, 'K': 55, 'L': 56, 'M': 57, 'N': 58, 'O': 59, 'P': 60, 'Q': 61, 'R': 62, 'S': 63, 'T': 64, 'U': 65, 'V': 66, 'W': 67, 'X': 68, 'Y': 69, 'Z': 70, '0': 71, '1': 72, '2': 73, '3': 74, '4': 75, '5': 76, '6': 77, '7': 78, '8': 79, '9': 80}\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "alphabet = \" ?%!.$\\\\:_-(){}[]\\\",+\" + string.ascii_lowercase + string.ascii_uppercase + string.digits\n",
    "char_to_idx = {c: alphabet.find(c) for c in alphabet}\n",
    "print(char_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in corpus:\n",
    "    for char in line:\n",
    "        if char not in alphabet:\n",
    "            assert char in alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(line):\n",
    "    result = []\n",
    "    for char in line:\n",
    "        row = [0] * len(alphabet)\n",
    "        row[char_to_idx[char]] = 1\n",
    "        result.append(row)\n",
    "    return result\n",
    "\n",
    "def idx_encode(line):\n",
    "    result = [char_to_idx[char] for char in line]\n",
    "    return result\n",
    "\n",
    "def sparse_tensor_encode(line):\n",
    "    assert False, \"TODO: implement sparse_tensor_encode\"\n",
    "    result = tf.sparse.SparseTensor(indices=[],\n",
    "                                    values = [],\n",
    "                                    dense_shape=[len(line), len(alphabet)])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input sequence\n",
    "seq_in = [idx_encode(line) for line in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "\n",
    "timesteps = None  # Length of your sequences\n",
    "input_dim = 1\n",
    "latent_dim = 30\n",
    "\n",
    "inputs = keras.Input(shape=(timesteps, input_dim))\n",
    "encoded = layers.LSTM(latent_dim)(inputs)\n",
    "\n",
    "decoded = layers.RepeatVector(timesteps)(encoded)\n",
    "decoded = layers.LSTM(input_dim, return_sequences=True)(decoded)\n",
    "\n",
    "sequence_autoencoder = keras.Model(inputs, decoded)\n",
    "encoder = keras.Model(inputs, encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/sinan/Projects.git/decode-the-spire/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/sinan/Projects.git/decode-the-spire/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/sinan/Projects.git/decode-the-spire/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/sinan/Projects.git/decode-the-spire/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/sinan/Projects.git/decode-the-spire/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/sinan/Projects.git/decode-the-spire/venv/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 235, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_10' (type Sequential).\n    \n    Input 0 of layer \"lstm_17\" is incompatible with the layer: expected ndim=3, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer 'sequential_10' (type Sequential):\n      • inputs=tf.Tensor(shape=(None,), dtype=int64)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# fit model\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_in\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_in\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m plot_model(model, show_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, to_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreconstruct_lstm_autoencoder.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# demonstrate recreation\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects.git/decode-the-spire/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filexzqtmwg6.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/sinan/Projects.git/decode-the-spire/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/sinan/Projects.git/decode-the-spire/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/sinan/Projects.git/decode-the-spire/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/sinan/Projects.git/decode-the-spire/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/sinan/Projects.git/decode-the-spire/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/sinan/Projects.git/decode-the-spire/venv/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 235, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_10' (type Sequential).\n    \n    Input 0 of layer \"lstm_17\" is incompatible with the layer: expected ndim=3, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer 'sequential_10' (type Sequential):\n      • inputs=tf.Tensor(shape=(None,), dtype=int64)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "# reproduction of inputs attempt\n",
    "num_samples = len(seq_in)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', input_shape=(len(seq_in[0]),1)))\n",
    "model.add(RepeatVector(n_in))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(array(seq_in[0]), array(seq_in[0]), epochs=300, verbose=2)\n",
    "plot_model(model, show_shapes=True, to_file='reconstruct_lstm_autoencoder.png')\n",
    "# demonstrate recreation\n",
    "yhat = model.predict(sequence, verbose=0)\n",
    "print(yhat[0,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
